# ğŸš€ Data Ingestion Agent - Complete Setup Guide

## ğŸ“‹ Overview

This is a **RAG (Retrieval Augmented Generation) system** that:
1. **Ingests data** from Discord servers and GitHub repositories
2. **Cleans and structures** the raw data
3. **Chunks** it into meaningful pieces
4. **Embeds** chunks into 768-dimensional vectors using Google's text-embedding-004
5. **Stores** everything in Neon PostgreSQL with pgvector
6. **Retrieves** relevant context and generates answers using Gemini 2.5

---

## ğŸ—ï¸ Architecture & Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     DATA SOURCES                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Discord Server    â”‚        GitHub Repos                   â”‚
â”‚   (messages, code)  â”‚    (code, docs, READMEs)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                          â”‚
           v                          v
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     1. DATA INGESTION (Raw Data)     â”‚
    â”‚  discord-pipeline/ | github-pipeline/â”‚
    â”‚  Stores in: Data table (JSON)        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       v
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   2. CLEANING (rag-pipeline/1.*.ts)  â”‚
    â”‚  - Remove noise, extract metadata    â”‚
    â”‚  - Stores in: CleanedData table      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       v
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  3. CHUNKING (rag-pipeline/2.*.ts)   â”‚
    â”‚  - Split into semantic chunks        â”‚
    â”‚  - Add context metadata              â”‚
    â”‚  - Stores in: Chunk table            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       v
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  4. EMBEDDING (rag-pipeline/3.*.ts)  â”‚
    â”‚  - Convert to 768-dim vectors        â”‚
    â”‚  - Google text-embedding-004         â”‚
    â”‚  - Stores: embedding column (vector) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       v
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚        NEON DB (PostgreSQL)          â”‚
    â”‚         with pgvector                â”‚
    â”‚  - Fast cosine similarity search     â”‚
    â”‚  - HNSW indexing                     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       v
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   5. RAG QUERY (rag-pipeline/4.*.ts) â”‚
    â”‚  - User asks question                â”‚
    â”‚  - Retrieve top-K similar chunks     â”‚
    â”‚  - Generate answer with Gemini 2.5   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Prerequisites

1. **Node.js/Bun** installed
2. **PostgreSQL database** (Neon recommended) with **pgvector** enabled
3. **Google Gemini API Key** ([Get it here](https://makersuite.google.com/app/apikey))
4. **Discord Bot Token** (optional, for Discord ingestion)
5. **GitHub Personal Access Token** (optional, for GitHub ingestion)

---

## âš™ï¸ Setup Instructions

### Step 1: Install Dependencies

```bash
cd data-agent
bun install
```

### Step 2: Configure Environment Variables

Create a `.env` file in the `data-agent/` folder:

```env
# Database (Neon PostgreSQL)
DATABASE_URL="postgresql://username:password@your-neon-host/neondb?sslmode=require"

# Google Gemini API Key (REQUIRED for embeddings & RAG)
GEMINI_API_KEY="your-gemini-api-key-here"

# Discord Bot Token (optional, only if using Discord ingestion)
DISCORD_TOKEN="your-discord-bot-token"

# GitHub Token (optional, only if using GitHub ingestion)
GITHUB_TOKEN="your-github-personal-access-token"
```

### Step 3: Run Database Migrations

```bash
cd data-agent
bunx prisma migrate dev
bunx prisma generate
```

### Step 4: Enable pgvector Extension

Run this SQL in your Neon SQL Editor:

```sql
CREATE EXTENSION IF NOT EXISTS vector;
```

---

## ğŸ¯ How to Use the System

### **Pipeline Order (Run these in sequence):**

#### Terminal 1: Start Data Ingestion Server(s)

**For Discord:**
```bash
cd data-agent
bun run discord-server.ts
```

**For GitHub:**
```bash
cd data-agent
bun run github-server.ts
```

These servers listen for incoming data and store raw data in the database.

---

#### Terminal 2: Run the RAG Pipeline

After data is ingested, run these steps **in order**:

**Step 1: Clean the raw data**
```bash
cd data-agent
bun run rag-pipeline/1.cleaning.ts
```

**Step 2: Chunk the cleaned data**
```bash
cd data-agent
bun run rag-pipeline/2.chunking.ts
```

**Step 3: Embed the chunks**
```bash
cd data-agent
bun run rag-pipeline/3.embedding.ts
```

**Step 4 (Optional): Create HNSW index for faster search**

After embeddings are created, run this SQL in Neon:

```sql
CREATE INDEX IF NOT EXISTS chunk_embedding_idx 
ON "Chunk" 
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);
```

---

#### Terminal 3: Query the System (RAG)

**Run the RAG query system:**
```bash
cd data-agent
bun run rag-pipeline/4.rag-query.ts
```

Or use it programmatically:

```typescript
import RAGQuery from "./rag-pipeline/4.rag-query";

const rag = new RAGQuery();

// Ask a question
const result = await rag.query("How do I set up TypeScript with Prisma?");

console.log(result.answer);
console.log("Sources:", result.sources);
```

---

## ğŸ“ File Structure

```
data-agent/
â”œâ”€â”€ rag-pipeline/
â”‚   â”œâ”€â”€ 1.cleaning.ts          # Cleans raw data
â”‚   â”œâ”€â”€ 2.chunking.ts          # Chunks cleaned data
â”‚   â”œâ”€â”€ 3.embedding.ts         # Embeds chunks (Google)
â”‚   â”œâ”€â”€ 4.rag-query.ts         # LangChain RAG with Gemini 2.5
â”‚   â””â”€â”€ create-index.sql       # SQL for HNSW index
â”‚
â”œâ”€â”€ discord-server.ts          # Discord MCP server
â”œâ”€â”€ github-server.ts           # GitHub MCP server
â”œâ”€â”€ db-client.ts               # Prisma client
â”œâ”€â”€ prisma.config.ts           # Prisma config
â”‚
â”œâ”€â”€ prisma/
â”‚   â”œâ”€â”€ schema.prisma          # Database schema
â”‚   â””â”€â”€ migrations/            # Database migrations
â”‚
â””â”€â”€ package.json
```

---

## ğŸ”„ Complete Workflow Example

### Scenario: You want to ingest Discord messages and query them

**Terminal 1: Start Discord Server**
```bash
cd data-agent
bun run discord-server.ts
```

**Terminal 2: Process Data**
```bash
# Wait for some messages to be ingested, then run:

cd data-agent

# Step 1: Clean
bun run rag-pipeline/1.cleaning.ts

# Step 2: Chunk
bun run rag-pipeline/2.chunking.ts

# Step 3: Embed
bun run rag-pipeline/3.embedding.ts
```

**Terminal 3: Query**
```bash
cd data-agent
bun run rag-pipeline/4.rag-query.ts
```

Or create your own query script:

```typescript
// my-query.ts
import RAGQuery from "./rag-pipeline/4.rag-query";

async function askQuestion() {
  const rag = new RAGQuery();
  
  const result = await rag.query(
    "What did users say about TypeScript?",
    "Discord", // Only search Discord messages
    5 // Top 5 results
  );
  
  console.log("\nğŸ“ Answer:\n", result.answer);
  console.log("\nğŸ“š Sources:\n", result.sources);
}

askQuestion();
```

---

## ğŸš¨ Troubleshooting

### "GEMINI_API_KEY not found"
- Make sure you have a `.env` file in `data-agent/` folder
- Add `GEMINI_API_KEY="your-key-here"`

### "No embedded chunks found"
- Run the embedding pipeline: `bun run rag-pipeline/3.embedding.ts`
- Make sure chunks exist: Check your database `Chunk` table

### "Error: relation 'vector' does not exist"
- Enable pgvector in Neon: `CREATE EXTENSION IF NOT EXISTS vector;`
- Run migrations: `bunx prisma migrate dev`

### Slow search performance
- Create the HNSW index (see Step 4 above)
- Only create index AFTER embeddings are generated

---

## ğŸ“Š Database Tables

| Table | Purpose |
|-------|---------|
| **Data** | Raw ingested data (JSON) |
| **CleanedData** | Cleaned, structured data |
| **Chunk** | Semantic chunks with embeddings (vector) |

---

## ğŸ“ Key Concepts

- **RAG**: Retrieval Augmented Generation - Retrieve relevant context before generating
- **Embedding**: Converting text to numerical vectors (768 dimensions)
- **pgvector**: PostgreSQL extension for vector similarity search
- **Cosine Similarity**: Measure of how similar two vectors are (0-1)
- **HNSW**: Fast approximate nearest neighbor search algorithm

---

## ğŸ”— Useful Links

- [Neon Database](https://neon.tech)
- [Google Gemini API](https://ai.google.dev)
- [pgvector Documentation](https://github.com/pgvector/pgvector)
- [LangChain Documentation](https://js.langchain.com)

---

## ğŸ“ Next Steps

1. âœ… Set up your `.env` file
2. âœ… Run migrations
3. âœ… Ingest some data (Discord/GitHub)
4. âœ… Run the RAG pipeline (clean â†’ chunk â†’ embed)
5. âœ… Create HNSW index
6. âœ… Start querying with Gemini 2.5!

Happy building! ğŸš€
